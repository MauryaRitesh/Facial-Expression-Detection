# 表情検出

これは、YouTube 上の リテシュ による [このビデオ](https://youtu.be/Dqa-3N8VZbw) のコードです。

顔の表情または顔の感情検出器を使用すると、人が悲しい、幸せ、怒っているなどを顔だけで知ることができます。このリポジトリは、そのようなタスクを実行するために使用できます。 Webカメラを使用して、リアルタイムで表情を識別します。そう、リアルタイムで！

# プラン

これは 3 つのステップからなるプロセスです。最初に、顔の存在を検出するために XML ファイルをロードし、次に 5 つの異なるカテゴリの画像を使用してネットワークを再トレーニングします。その後、[最後のビデオ]() から label_image.py プログラムをインポートし、すべてをリアルタイムでセットアップします。

# 依存関係

まだインストールしていない場合は、CMD/ターミナルで次のコマンドを実行します。

    pip install tensorflow
    pip install opencv-python

今のところはそれだけです。

それでは、各ステップを簡単に見てみましょう。

## ステップ 1 - OpenCV HAAR カスケードの実装

Web カメラ内の顔の存在を検出するために「Frontal Face Alt」分類子を使用しています。このファイルはこのリポジトリに含まれています。他の分類子は [ここ](https://github.com/opencv/opencv/tree/master/data/haarcascades) で見つけることができます。

次に、このファイルをロードするタスクがあります。このファイルは [label.py](https://github.com/MauryaRitesh/Facial-Expression-Detection/blob/master/label.py) プログラムにあります。例えば。：

     # We load the xml file
     classifier = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')

これで、Label.py プログラムを使用してすべてを設定できるようになりました。それでは、次のステップに進みましょう。

## ステップ 2 - ネットワークの再トレーニング - Tensorflow 画像分類子

人が悲しいか幸せかなどを識別する画像分類子を作成し、このテキストを OpenCV ウィンドウに表示します。
このステップは、いくつかのサブステップで構成されます。

- まず、images という名前のディレクトリを作成する必要があります。このディレクトリに、Happy、Sad、Angry、Calm、Neutral などの名前を付けた 5 つまたは 6 つのサブディレクトリを作成します。これ以外にも追加できます。
- 次に、インターネットからイメージをダウンロードして、これらのディレクトリにそれぞれのイメージを入力します。たとえば、「Happy」ディレクトリには、幸せな人のイメージだけを記入します。
- [ビデオ](https://youtu.be/Dqa-3N8VZbw) で提案されているように、「face-crop.py」プログラムを実行します。
- イメージのみをクリーニングしたら、ネットワークを再トレーニングする準備が整います。この目的のために、私は非常に高速で正確な Mobilenet モデルを使用しています。トレーニングを実行するには、「get」を押して親フォルダーに移動し、ここで CMD/ターミナル を開き、次のコマンドを押します。

      python retrain.py --output_graph=retrained_graph.pb --output_labels=retrained_labels.txt --architecture=MobileNet_1.0_224 --image_dir=images

このステップはこれで終わりです。

## ステップ 3 - 再トレーニングされたモデルのインポートとすべてのセットアップ

最後に、すべてを「label_image.py」ファイルの下に置きました。ここからすべてを入手できます。
次に、CMD/ターミナルに次のように入力して、「label.py」プログラムを実行します。

     python label.py

OpenCV の新しいウィンドウが開き、あなたの顔の表情が識別されます。
これで完了です！

## 貢献ガイドライン
「表情検出」プロジェクトへの貢献をご検討いただきありがとうございます。

OpenCV の新しいウィンドウが開き、あなたの顔の表情が識別されます。
これで完了です！

## 貢献ガイドライン
「表情検出」プロジェクトへの貢献をご検討いただきありがとうございます。
＃＃＃ はじめる

1.リポジトリをフォークする: 貢献するには、メイン リポジトリを GitHub アカウントにフォークします。

2.リポジトリのクローンを作成します: フォークされたリポジトリのクローンをローカル マシンに作成します。


    git clone https://github.com/MauryaRitesh/Facial-Expression-Detection.git

3.開発環境のセットアップ: 必要な依存関係をまだインストールしていない場合はインストールします。これを行うには、次のコマンドを実行します。
```python
pip install tensorflow
pip install opencv-python
```

4. ブランチの作成: 投稿用に新しいブランチを作成します。あなたの貢献の性質を反映した、ブランチのわかりやすい名前を選択してください。
```bash
git checkout -b feature/your-feature-name
```

5.変更を加えます: ブランチに必要な変更と追加を加えま​​す。

6.変更をコミットする: 明確かつ簡潔で、十分に文書化されたコミット メッセージを作成します。関連する問題やプル リクエストをコミット内で参照します。

```bash
git commit -m "Add new feature"
```

7.変更をプッシュする: ブランチを GitHub リポジトリにプッシュします。
```bash
git push origin feature/your-feature-name
```

8.プル リクエストの作成: フォークされたリポジトリからメイン リポジトリへのプル リクエストを作成します。


興味深いものを見つけた場合は、このリポジトリにスターを付けてください。 <3
